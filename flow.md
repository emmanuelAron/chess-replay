(Mode 1)

[ User ]
|
| 1. Click "Chigorin"
v
[ Frontend React ]
|
| 2. POST /replay/espagnole/CHIGORIN
v
[ Spring Boot Backend ]
|
| 3. Load moves (memory / file / service)
| 4. Iterate moves
|
| 5. send(move)
v
[ WebSocket Handler ]
|
| 6. push move
v
[ Frontend Chessboard ]

--------------
(Mode 2)
[ User ]
|
| 1. Click "Chigorin"
v
[ Frontend React ]
|
| 2. POST /replay/espagnole/CHIGORIN
v
[ Spring Boot Backend ]
|
| 3. Load moves
| 4. For each move:
|      publish MOVE_PLAYED
v
[ Kafka Topic : chess.events ]
|
|-----------------------------|
|                             |
v                             v
[ Consumer A ]                  [ Consumer B ]
[ Replay WS ]                   [ Analytics ]
|                             |
| 5. broadcast                | 6. compute stats
v                             v
[ WebSocket ]                [ Spark Streaming ]
|                             |
v                             v
[ Frontend Board ]         [ MongoDB / Aggregates ]





-----------------------------------------------------

A. Mode 2 â€” Replay + Analytics (interactif, user-driven)

ğŸ‘‰ Objectif :

rejouer une partie ou un petit groupe

voir lâ€™Ã©chiquier bouger

calculer des stats en mÃªme temps

ğŸ§± Flow dÃ©taillÃ©
[ User clicks "Replay + Analytics" ]
|
v
[ Frontend React ]
|
| POST /replay/espagnole/CHIGORIN
v
[ Spring Boot Backend ]
|
| load ONE game (JSONL / memory / service)
| for each move:
|   build MOVE_PLAYED event
|   publish to Kafka
v
[ Kafka topic : chess.events ]
|
|-----------------------------|
|                             |
v                             v
[ Replay Consumer ]           [ Analytics Consumer ]
[ Spring Boot ]               [ Spark Streaming ]
|                             |
| broadcast WS                | aggregate stats
v                             v
[ Frontend Board ]          [ MongoDB (aggregates) ]

ğŸ”‘ Points clÃ©s

âŒ pas toutes les parties

âŒ pas de stockage brut

âœ… 1 partie â†’ ~40 events

âœ… stats calculÃ©es pendant le replay

ğŸ”¹ B. Mode Batch Analytics (offline, data-driven)

ğŸ‘‰ Objectif :

analyser des milliers de parties

remplir Mongo

prÃ©parer dashboards

ğŸ§± Flow dÃ©taillÃ©
[ Batch Job Trigger ]
|
v
[ Batch Producer ]
(read JSONL / PGN)
|
| publish MOVE_PLAYED events (streamed)
v
[ Kafka topic : chess.events ]
|
v
[ Spark Streaming ]
|
| windowing
| grouping
| aggregation
v
[ MongoDB ]
(opening stats, winrate, length, etc.)

ğŸ”‘ Points clÃ©s

Kafka = tampon

Spark = consommateur unique

Mongo = rÃ©sultat final

âŒ aucun frontend impliquÃ©






-----------------------------
(Mode 2)
ReplayEngine
â†“
KafkaEventPublisher
â†“
Kafka topic: chess.events
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ websocket-replay (Spring)     â”‚ analytics-java (Spring)      â”‚
â”‚ ReplayKafkaConsumer           â”‚ AnalyticsKafkaConsumer       â”‚
â”‚ â†’ WebSocket â†’ UI              â”‚ â†’ Mongo (events / stats)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


